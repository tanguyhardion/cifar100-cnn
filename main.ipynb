{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN on CIFAR-100\n",
    "\n",
    "Author : **Tanguy Hardion**\n",
    "\n",
    "## Introduction\n",
    "\n",
    "### Objective\n",
    "\n",
    "The objective of this project is to train a model to classify images. We will create and train the model from scratch using an image dataset that we will preprocess.\n",
    "\n",
    "### Method\n",
    "\n",
    "We will use supervised **deep learning** and create a **convolutional neural network** (CNN) to train our model. We will use the `tensorflow` library.\n",
    "\n",
    "### Dataset\n",
    "\n",
    "There are many labeled image datasets. For this project, I have chosen the **CIFAR-100** dataset. It consists of 60,000 color images of 32x32 pixels, labeled in two ways:\n",
    "\n",
    "- **Coarse labels**: 20 classes (broad categories)\n",
    "- **Fine labels**: 100 classes (subcategories)\n",
    "\n",
    "For this project, we will use the **fine labels** because they allow for more precise classification, making for a more interesting deep learning exercise.\n",
    "\n",
    "CIFAR-100 is divided into 50,000 training images and 10,000 test images. The dataset is available on [HuggingFace](https://huggingface.co/datasets/uoft-cs/cifar100), and that's where we'll retrieve it from. All labels are integers, and the class names are available on HuggingFace or later in this notebook (in the variable `fine_labels_dict`, used during testing).\n",
    "\n",
    "### Project Content\n",
    "\n",
    "- This `.ipynb` notebook containing the outputs of the code cells from my last execution for clarity\n",
    "- A `requirements.txt` file specifying the necessary packages\n",
    "- A `cifar100_model.keras` file containing the trained model (if you don't want to train it yourself)\n",
    "\n",
    "## Notes\n",
    "\n",
    "### Versions\n",
    "\n",
    "Python version used: `3.11.9`. Issues may arise with TensorFlow in version `3.12`.\n",
    "\n",
    "TensorFlow version used: `2.16.1`. Note that if you don't use this TensorFlow version, the provided model might not load.\n",
    "\n",
    "All necessary packages are listed in the `requirements.txt` file. To install them, you can use the following command:\n",
    "\n",
    "```bash\n",
    "pip install -r requirements.txt\n",
    "```\n",
    "\n",
    "### Training\n",
    "\n",
    "Training can take a while, depending on your machine's processing power. To speed up the process, you can reduce the number of epochs or use a more powerful processor, or a GPU. Google Colab provides powerful GPUs for free, suitable for this kind of task."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Library Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Input, Conv2D, Dense, Flatten, Dropout\n",
    "from tensorflow.keras.layers import MaxPooling2D\n",
    "from tensorflow.keras.layers import BatchNormalization\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.metrics import SparseCategoricalAccuracy\n",
    "\n",
    "from datasets import load_dataset\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the dataset from HuggingFace"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train split : 50 000 images\n",
    "train_dataset = load_dataset(\"cifar100\", split=\"train\")\n",
    "\n",
    "# Test split : 10 000 images\n",
    "test_dataset = load_dataset(\"cifar100\", split=\"test\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization of useful variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Number of classes (\"fine_label\"): 100\n",
    "num_classes = len(train_dataset.features[\"fine_label\"].names)\n",
    "print(f\"Number of classes: {num_classes}\")\n",
    "\n",
    "# Image size: 32x32 pixels with 3 color channels (RGB)\n",
    "image_shape = np.array(train_dataset[0][\"img\"]).shape\n",
    "print(f\"Image size: {image_shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Labels dictionary (copied from the dataset documentation)\n",
    "fine_labels_dict = {\n",
    "    0: \"apple\",\n",
    "    1: \"aquarium_fish\",\n",
    "    2: \"baby\",\n",
    "    3: \"bear\",\n",
    "    4: \"beaver\",\n",
    "    5: \"bed\",\n",
    "    6: \"bee\",\n",
    "    7: \"beetle\",\n",
    "    8: \"bicycle\",\n",
    "    9: \"bottle\",\n",
    "    10: \"bowl\",\n",
    "    11: \"boy\",\n",
    "    12: \"bridge\",\n",
    "    13: \"bus\",\n",
    "    14: \"butterfly\",\n",
    "    15: \"camel\",\n",
    "    16: \"can\",\n",
    "    17: \"castle\",\n",
    "    18: \"caterpillar\",\n",
    "    19: \"cattle\",\n",
    "    20: \"chair\",\n",
    "    21: \"chimpanzee\",\n",
    "    22: \"clock\",\n",
    "    23: \"cloud\",\n",
    "    24: \"cockroach\",\n",
    "    25: \"couch\",\n",
    "    26: \"cra\",\n",
    "    27: \"crocodile\",\n",
    "    28: \"cup\",\n",
    "    29: \"dinosaur\",\n",
    "    30: \"dolphin\",\n",
    "    31: \"elephant\",\n",
    "    32: \"flatfish\",\n",
    "    33: \"forest\",\n",
    "    34: \"fox\",\n",
    "    35: \"girl\",\n",
    "    36: \"hamster\",\n",
    "    37: \"house\",\n",
    "    38: \"kangaroo\",\n",
    "    39: \"keyboard\",\n",
    "    40: \"lamp\",\n",
    "    41: \"lawn_mower\",\n",
    "    42: \"leopard\",\n",
    "    43: \"lion\",\n",
    "    44: \"lizard\",\n",
    "    45: \"lobster\",\n",
    "    46: \"man\",\n",
    "    47: \"maple_tree\",\n",
    "    48: \"motorcycle\",\n",
    "    49: \"mountain\",\n",
    "    50: \"mouse\",\n",
    "    51: \"mushroom\",\n",
    "    52: \"oak_tree\",\n",
    "    53: \"orange\",\n",
    "    54: \"orchid\",\n",
    "    55: \"otter\",\n",
    "    56: \"palm_tree\",\n",
    "    57: \"pear\",\n",
    "    58: \"pickup_truck\",\n",
    "    59: \"pine_tree\",\n",
    "    60: \"plain\",\n",
    "    61: \"plate\",\n",
    "    62: \"poppy\",\n",
    "    63: \"porcupine\",\n",
    "    64: \"possum\",\n",
    "    65: \"rabbit\",\n",
    "    66: \"raccoon\",\n",
    "    67: \"ray\",\n",
    "    68: \"road\",\n",
    "    69: \"rocket\",\n",
    "    70: \"rose\",\n",
    "    71: \"sea\",\n",
    "    72: \"seal\",\n",
    "    73: \"shark\",\n",
    "    74: \"shrew\",\n",
    "    75: \"skunk\",\n",
    "    76: \"skyscraper\",\n",
    "    77: \"snail\",\n",
    "    78: \"snake\",\n",
    "    79: \"spider\",\n",
    "    80: \"squirrel\",\n",
    "    81: \"streetcar\",\n",
    "    82: \"sunflower\",\n",
    "    83: \"sweet_pepper\",\n",
    "    84: \"table\",\n",
    "    85: \"tank\",\n",
    "    86: \"telephone\",\n",
    "    87: \"television\",\n",
    "    88: \"tiger\",\n",
    "    89: \"tractor\",\n",
    "    90: \"train\",\n",
    "    91: \"trout\",\n",
    "    92: \"tulip\",\n",
    "    93: \"turtle\",\n",
    "    94: \"wardrobe\",\n",
    "    95: \"whale\",\n",
    "    96: \"willow_tree\",\n",
    "    97: \"wolf\",\n",
    "    98: \"woman\",\n",
    "    99: \"worm\",\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Quick dataset exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Dataset shape: \", train_dataset.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Displaying some random images with their labels\n",
    "\n",
    "As the images are 32x32 pixels, they are quite small, explaining the low resolution in the images below. However, this will be enough to train our deep learning model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(3):\n",
    "    random_index = random.randint(0, len(train_dataset))\n",
    "    random_image = train_dataset[random_index][\"img\"]\n",
    "    random_label = train_dataset[random_index][\"fine_label\"]\n",
    "    plt.figure(figsize=(2, 2))\n",
    "    plt.title(f\"Label: {fine_labels_dict[random_label]}\")\n",
    "    plt.axis(\"off\")\n",
    "    plt.imshow(random_image)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image preprocessing\n",
    "\n",
    "We will now preprocess the images to make them usable by our deep learning model. The images are already normalized (pixel values between 0 and 1), but we will:\n",
    "\n",
    "- Convert them to `tf.float32` to use with TensorFlow\n",
    "- Resize them to ensure they are 32x32 pixels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_image(image, label):\n",
    "    \"\"\"\n",
    "    Preprocesses images.\n",
    "    Converts the image to tf.float32 and resizes it to 32x32 pixels.\n",
    "    \"\"\"\n",
    "\n",
    "    image = tf.image.convert_image_dtype(image, tf.float32)\n",
    "    image = tf.image.resize(image, [32, 32])\n",
    "    return image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data generator function\n",
    "\n",
    "In Python, a generator is a function that loads data into memory as needed during training, preventing memory overload and enabling the training of models on large datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(dataset):\n",
    "    \"\"\"\n",
    "    Generates images and labels.\n",
    "    From the given dataset, returns a tuple (image, label).\n",
    "\n",
    "    If the image is in 2D (grayscale), it is duplicated across 3 channels to ensure all images have the same shape.\n",
    "    \"\"\"\n",
    "\n",
    "    for element in dataset:\n",
    "        # Retrieve image and label\n",
    "        image = np.array(element[\"img\"])\n",
    "        label = element[\"fine_label\"]\n",
    "\n",
    "        # Duplicate 2D images across 3 channels\n",
    "        if image.ndim == 2:\n",
    "            image = np.stack([image] * 3, axis=-1)\n",
    "\n",
    "        yield image, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating TensorFlow datasets\n",
    "\n",
    "TensorFlow uses `tf.data.Dataset` objects to handle data. We will create these objects for training and testing using the functions we just defined."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training dataset\n",
    "train_dataset_tf = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(train_dataset),\n",
    "\n",
    "    # Output signature: tuple (image, label)\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=image_shape, dtype=tf.uint8),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int64),\n",
    "    ),\n",
    ")\n",
    "\n",
    "# Testing dataset\n",
    "test_dataset_tf = tf.data.Dataset.from_generator(\n",
    "    lambda: generator(test_dataset),\n",
    "\n",
    "    # Output signature: tuple (image, label)\n",
    "    output_signature=(\n",
    "        tf.TensorSpec(shape=image_shape, dtype=tf.uint8),\n",
    "        tf.TensorSpec(shape=(), dtype=tf.int64),\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Appyling preprocessing functions to the datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We're now going to apply the preprocessing to our TensorFlow datasets. Below, we will:\n",
    "\n",
    "- Apply the `preprocess_image` function to each image in the dataset\n",
    "\n",
    "- Create batches of 32 images for training. A batch is a set of images that will be processed at the same time by the model.\n",
    "\n",
    "- Preload the images to speed up the process (`prefetch`), letting TensorFlow dynamically adjust the number of images (`tf.data.AUTOTUNE`)\n",
    "\n",
    "- Repeat the images so they are used multiple times during training (`repeat`, in this case `2` times). This increases the number of images (batches) per epoch. We could also simply increase the number of epochs, but increasing the dataset size will give us faster training (since fewer epochs = fewer validation steps).\n",
    "\n",
    "Shuffling (`shuffle`) is not necessary here, as CIFAR-100 is already shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting batch size at 32 (a common value)\n",
    "batch_size = 32\n",
    "\n",
    "train_dataset_tf_preprocessed = (\n",
    "    train_dataset_tf.map(preprocess_image).batch(batch_size).prefetch(tf.data.AUTOTUNE).repeat(2)\n",
    ")\n",
    "\n",
    "test_dataset_tf_preprocessed = (\n",
    "    test_dataset_tf.map(preprocess_image).batch(batch_size).prefetch(tf.data.AUTOTUNE)\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model creation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Neural Network Architecture\n",
    "\n",
    "We will now create our deep learning model. We will use a Convolutional Neural Network (CNN) to process the images. A CNN is a type of neural network that is very effective for handling spatial data, such as images.\n",
    "\n",
    "We will detail the structure directly in the code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_cnn(input_shape, n_classes):\n",
    "    \"\"\"\n",
    "    Creates a simple convolutional neural network model\n",
    "    based on an input of shape `input_shape` and `n_classes` output classes.\n",
    "    \"\"\"\n",
    "\n",
    "    # Input layer of shape `input_shape`\n",
    "    inputs = Input(shape=input_shape)\n",
    "\n",
    "    # First convolution block\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(inputs)  # 32 filters of size 3x3\n",
    "    x = BatchNormalization()(x)  # Normalization of the previous layer's activations (to speed up learning)\n",
    "    x = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)  # Reduces image size by a factor of 2 (to make the model more efficient)\n",
    "    x = Dropout(0.2)(x)  # Randomly disables 20% of neurons (regularization, to avoid overfitting)\n",
    "\n",
    "    # Second convolution block (same as the first, but with more filters and a higher dropout)\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.3)(x)\n",
    "\n",
    "    # Third convolution block (same as the second, but with even more filters and an even higher dropout)\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D(pool_size=(2, 2))(x)\n",
    "    x = Dropout(0.4)(x)\n",
    "\n",
    "    # Output layer\n",
    "    x = Flatten()(x)  # Converts the 3D output to a 1D vector\n",
    "    x = Dense(512, activation=\"relu\")(x)  # Dense layer with 512 neurons, using ReLU activation function\n",
    "    x = Dropout(0.5)(x)  # 50% dropout (to avoid overfitting)\n",
    "    outputs = Dense(n_classes, activation=\"softmax\")(x)  # Output layer with softmax activation function\n",
    "\n",
    "    model = Model(inputs, outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creation and compilation of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = create_cnn(image_shape, num_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    # Adam gradient descent algorithm, with a default learning rate (0.001)\n",
    "    optimizer=Adam(),\n",
    "    # Loss function for a multi-class classification problem\n",
    "    loss=SparseCategoricalCrossentropy(),\n",
    "    # To measure model accuracy during training\n",
    "    metrics=[SparseCategoricalAccuracy()],\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now display a summary of the model to see its structure."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution\n",
    "\n",
    "Our model is now ready to be trained. We will start the training with the `fit` function and store the results in the object `r`, which will contain the training results.\n",
    "\n",
    "#### Epochs\n",
    "\n",
    "We're using 10 epochs for training here (~1h with an i5 9th Gen), but you can increase or decrease this number based on your machine's performance. Ideally, we would want a higher number of epochs for better training, but without Colab or a GPU, it can take a long time.\n",
    "\n",
    "Knowing that 5 epochs are enough to get about **40%** accuracy, if you want to train the model yourself, I suggest reducing the number of epochs to 5, which will already give you a good idea of the model's performance.\n",
    "\n",
    "No worries, if you don't like waiting, you can skip directly to the next part to load and test the pre-trained model provided in the `model` folder.\n",
    "\n",
    "#### Validation\n",
    "\n",
    "At the end of each epoch, the model is tested with validation data (the test dataset) to monitor its progress over the epochs. Our model will not be trained on `test_dataset_tf_preprocessed`, naturally, allowing us to reuse this split for testing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = model.fit(\n",
    "    x=train_dataset_tf_preprocessed,\n",
    "    validation_data=test_dataset_tf_preprocessed,\n",
    "    epochs=10\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualization of the results\n",
    "\n",
    "We can now visualize the training results. We will plot the accuracy and loss curves for training and validation, which will allow us to see if our model has learned well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss\n",
    "plt.plot(r.history['loss'])\n",
    "\n",
    "# Accuracy\n",
    "plt.plot(r.history['sparse_categorical_accuracy'])\n",
    "\n",
    "# Loss (validation)\n",
    "plt.plot(r.history['val_loss'])\n",
    "\n",
    "# Accuracy (validation)\n",
    "plt.plot(r.history['val_sparse_categorical_accuracy'])\n",
    "\n",
    "plt.legend(['loss', 'accuracy', 'val_loss', 'val_accuracy'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that accuracy increases over epochs, and loss decreases. This is a good sign, indicating that our model is learning well.\n",
    "\n",
    "However, we also see that the accuracy increases less and less over epochs, and the loss decreases less and less. This is normal, as the more the model learns, the harder it is to improve its performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Testing the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation\n",
    "\n",
    "Now that our model is trained, we will evaluate its performance using the test dataset. We will use the `evaluate` function to evaluate the model on test images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_loss, test_accuracy = model.evaluate(test_dataset_tf_preprocessed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With 10 epochs, we achieve an accuracy higher than **50%**. This is a good score, but it could obviously be improved by increasing the number of epochs and the size of the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interactive testing\n",
    "\n",
    "To see how our model behaves on test images, we will create a `test_model` function that predicts the labels of a certain number of random images and displays the images with their true label as well as the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_model(model, test_dataset, num_samples):\n",
    "    \"\"\"\n",
    "    Uses the `model` parameter to predict `num_samples` labels\n",
    "    from the `test_dataset`.\n",
    "    Displays the images with their label and associated predictions.\n",
    "    \"\"\"\n",
    "\n",
    "    # Randomly retrieve images\n",
    "    indices = random.sample(range(len(test_dataset)), num_samples)\n",
    "    sample_images = [test_dataset[i][\"img\"] for i in indices]\n",
    "    sample_labels = [test_dataset[i][\"fine_label\"] for i in indices]\n",
    "\n",
    "    # Preprocess retrieved images\n",
    "    sample_images_preprocessed = [preprocess_image(img, label)[0].numpy() for img, label in zip(sample_images, sample_labels)]\n",
    "    sample_images_preprocessed = np.array(sample_images_preprocessed)\n",
    "\n",
    "    # Predict labels\n",
    "    predictions = model.predict(sample_images_preprocessed)\n",
    "    predicted_labels = np.argmax(predictions, axis=1)\n",
    "\n",
    "    # Display results\n",
    "    plt.figure(figsize=(20, 20))\n",
    "    for i in range(num_samples):\n",
    "        plt.subplot(1, num_samples, i+1)\n",
    "        plt.imshow(sample_images[i])\n",
    "        true_label = fine_labels_dict[sample_labels[i]]\n",
    "        predicted_label = fine_labels_dict[predicted_labels[i]]\n",
    "        plt.title(f'True: {true_label}\\nPred: {predicted_label}')\n",
    "        plt.axis('off')\n",
    "\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's use the function to display and predict the labels of 10 images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(model, test_dataset, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe that our model correctly predicts most images. This means that our model has learned well and is capable of generalizing to images it has never seen.\n",
    "\n",
    "Moreover, we notice that when the model makes mistakes, it still predicts labels that are quite close to reality. It will correctly predict an animal but get the species wrong, for example. The same goes for plants, vehicles, etc. If we had used the dataset with `coarse labels`, the model would probably have been more accurate, as the classes are more general.\n",
    "\n",
    "Some images are difficult to predict, even for a human. This is normal, as CIFAR-100 is a difficult dataset with low-resolution images and very similar classes."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Saving the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sauvegardons le modèle pour pouvoir le réutiliser plus tard."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('cifar100_model.keras')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If you couldn't train the model, let's load the provided version and test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded_model = tf.keras.models.load_model('cifar100_model.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_model(loaded_model, test_dataset, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My method for recognizing CIFAR-100 images, a CNN model, is advantageous because it allows for good accuracy with a **simple architecture**, not a lot of **data**, and a **reasonable** training time.\n",
    "\n",
    "Obviously, this model is not perfect, and there are many ways to improve it. We could, for example:\n",
    "\n",
    "- Use a more complex model (more layers, more neurons)\n",
    "- Increase the number of epochs\n",
    "- Increase the size of the dataset\n",
    "- Experiment even more with the neural network architecture to find the best possible configuration\n",
    "\n",
    "Nevertheless, I am very happy with this deep learning project. By going up to **50 epochs** on Google Colab, I was able to achieve over **70%** accuracy on the test dataset, which is a very good score for such a model. You can check the plot of the accuracy and loss with 50 epochs on the repo.\n",
    "\n",
    "In comparison, deep learning models on [ImageNet](https://paperswithcode.com/sota/image-classification-on-imagenet) achieve accuracies of **90%** and more, but they are trained on many more higher-quality images with much more complex architectures (*2 billion* parameters for some models, compared to *4 million* for mine).\n",
    "\n",
    "I am therefore very satisfied with this project, and I look forward to continuing to explore the world of deep learning and artificial intelligence."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
